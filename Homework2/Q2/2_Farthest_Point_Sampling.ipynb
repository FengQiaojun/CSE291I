{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "import heapq\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the area of an triangle\n",
    "# input is a 3*3 matrix, with each row a vertices in 3d space\n",
    "def triangles_area(vertices):\n",
    "    v1 = vertices[1] - vertices[0]\n",
    "    v2 = vertices[2] - vertices[0]\n",
    "    cross = np.cross(v1,v2)\n",
    "    area = np.linalg.norm(cross)/2\n",
    "    return area\n",
    "\n",
    "# function to compute the area of an triangle\n",
    "# input is a 3*3 matrix, with each row a vertices in 3d space\n",
    "# using Heron's formula \n",
    "def triangles_area_Heron(vertices):\n",
    "    a = np.linalg.norm(vertices[2]-vertices[0])\n",
    "    b=np.linalg.norm(vertices[2]-vertices[1])\n",
    "    c=np.linalg.norm(vertices[1]-vertices[0])\n",
    "    p = (a+b+c)/2\n",
    "    area = np.sqrt(p*(p-a)*(p-b)*(p-c))\n",
    "    return area\n",
    "\n",
    "# function that return all the triangle faces' area\n",
    "def triangle_faces_area(vertices,faces):\n",
    "    n_faces = faces.shape[0]\n",
    "    area = np.zeros(n_faces)\n",
    "    for index_face in range(n_faces):\n",
    "        area[index_face] = triangles_area_Heron(vertices[faces[index_face]])\n",
    "    return area\n",
    "\n",
    "\n",
    "# read the vertices and faces data\n",
    "# have been stored in the .pkl form\n",
    "# calculate the area of all the triangles in the mesh\n",
    "\n",
    "\"\"\"\n",
    "vertices = pickle.load(open('teapot_vertices.pkl', 'rb'))\n",
    "faces = pickle.load(open('teapot_faces.pkl', 'rb'))\n",
    "if os.path.isfile('teapot_area.pkl'):\n",
    "    area = pickle.load(open('teapot_area.pkl', 'rb'))\n",
    "else:\n",
    "    area = triangle_faces_area(teapot_vertices,teapot_faces)\n",
    "    output = open('teapot_area.pkl', 'wb')\n",
    "    pickle.dump(area, output)\n",
    "    output.close()\n",
    "\"\"\"\n",
    "obj = 'violin_case'\n",
    "vertices = pickle.load(open(obj+'_vertices.pkl', 'rb'))\n",
    "faces = pickle.load(open('violin_case_faces.pkl', 'rb'))\n",
    "if os.path.isfile('violin_case_area.pkl'):\n",
    "    area = pickle.load(open('violin_case_area.pkl', 'rb'))\n",
    "else:\n",
    "    area = triangle_faces_area(violin_case_vertices,violin_case_faces)\n",
    "    output = open('violin_case_area.pkl', 'wb')\n",
    "    pickle.dump(area, output)\n",
    "    output.close()\n",
    "\n",
    "\n",
    "# transform to weight and assign number of sampling point on each faces\n",
    "# N is total sampling points' number: point set P\n",
    "N = 11000\n",
    "sample_number = N*np.round(area/np.sum(area),np.log10(N).astype(int))\n",
    "sample_number = sample_number.astype(int)\n",
    "N_sample = np.sum(sample_number).astype(int)\n",
    "\n",
    "P = np.zeros([N_sample,3])\n",
    "P_face = np.zeros(N_sample)\n",
    "index_sample = 0\n",
    "for index_face in range(faces.shape[0]):\n",
    "    vertice_coordinate = vertices[faces[index_face]]\n",
    "    for index_sample_mesh in range(sample_number[index_face]):\n",
    "        r1 = np.random.uniform()\n",
    "        r2 = np.random.uniform()\n",
    "        P[index_sample] = (1-np.sqrt(r1))*vertice_coordinate[0] + \\\n",
    "                                    np.sqrt(r1)*(1-r2)*vertice_coordinate[1] + \\\n",
    "                                    np.sqrt(r1)*r2*vertice_coordinate[2]\n",
    "        P_face[index_sample] = index_face\n",
    "        index_sample = index_sample + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertice_distance_init(vertices,faces):\n",
    "    N = vertices.shape[0]\n",
    "    D = np.zeros([N,N])\n",
    "    D[:] = np.inf\n",
    "    for index in range(N):\n",
    "        D[index][index] = 0\n",
    "    for index_face in range(faces.shape[0]):\n",
    "        [index_a,index_b,index_c] = faces[index_face]\n",
    "        D[index_a][index_b] = np.linalg.norm(vertices[index_a]-vertices[index_b])\n",
    "        D[index_b][index_a] = np.linalg.norm(vertices[index_a]-vertices[index_b])\n",
    "        D[index_a][index_c] = np.linalg.norm(vertices[index_a]-vertices[index_c])\n",
    "        D[index_c][index_a] = np.linalg.norm(vertices[index_a]-vertices[index_c])\n",
    "        D[index_b][index_c] = np.linalg.norm(vertices[index_c]-vertices[index_b])\n",
    "        D[index_c][index_b] = np.linalg.norm(vertices[index_c]-vertices[index_b])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a point cloud with n points, using k nearest-neighbors algorithm to build a graph on it\n",
    "# return the distance matrix(n*n) of the graph. Inf means not edge between 2 points\n",
    "# 1. make sure each edge is bilateral\n",
    "# 2. make sure the full connectivity, i.e. any point can reach any point\n",
    "# Because of the request above, degree of each point may vary\n",
    "# if return nan, means that some points are not connected to the others\n",
    "# maybe you may want to increase k\n",
    "\n",
    "def knn_distance_init(points,k):\n",
    "    k = 5\n",
    "    N = points.shape[0]\n",
    "    # calculate the distance matrix between each pair of points\n",
    "    Dist = scipy.spatial.distance.cdist(points,points)\n",
    "    # initialize a distance matrix and set all the elements to zero\n",
    "    D = np.zeros(Dist.shape)\n",
    "    D[:] = np.inf\n",
    "    # for each point, find its (k+1) values that are the minimal(because including 0)\n",
    "    # assign them to matrix D\n",
    "    for index_point in range(N):\n",
    "        k_smallest_index = np.argpartition(Dist[index_point], k+1)[:k+1]\n",
    "        D[index_point][k_smallest_index] = Dist[index_point][k_smallest_index]\n",
    "    # 1. make sure each edge is bilateral\n",
    "    # by comparing D[i][j] and D[j][i]\n",
    "    # let D[i][j]=D[j][i] = min(D[i][j],D[j][i])\n",
    "    for index_i in range(N):\n",
    "        for index_j in range(index_i+1,N):\n",
    "            if D[index_i][index_j] != D[index_j][index_i]:\n",
    "                D_min = np.min([D[index_i][index_j],D[index_j][index_i]])\n",
    "                D[index_i][index_j] = D_min\n",
    "                D[index_j][index_i] = D_min\n",
    "    # 2. make sure the full connectivity\n",
    "    # by expanding from one point till the end\n",
    "    check_connection = np.zeros(N)\n",
    "    check_connection[0] = 1\n",
    "    open_list = [0]\n",
    "    for iters in range(N-1):\n",
    "        if len(open_list) == 0:\n",
    "            return np.array(np.nan)\n",
    "        else:\n",
    "            open_node = open_list[0]\n",
    "        open_list.remove(open_node)\n",
    "        neighbor_nodes = list(np.where(np.isfinite(D[open_node]))[0])\n",
    "        neighbor_nodes.remove(open_node)\n",
    "        # only keep the neighbor that hasn't been visited before\n",
    "        neighbor_keep = []\n",
    "        for index_neighbor in range(len(neighbor_nodes)):\n",
    "            if check_connection[neighbor_nodes[index_neighbor]] != 1:\n",
    "                neighbor_keep.extend([index_neighbor])\n",
    "        neighbor_nodes_keep = [neighbor_nodes[i] for i in neighbor_keep]\n",
    "        open_list.extend(neighbor_nodes_keep)\n",
    "        check_connection[neighbor_nodes_keep] = 1\n",
    "        if np.sum(check_connection) == N:\n",
    "            return D\n",
    "    if np.sum(check_connection) == N:\n",
    "        return D\n",
    "    else:\n",
    "        return np.array(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the previous vertices and part of the sampled points\n",
    "# to build a full-connected, bilateral graph\n",
    "# but with less points than the whole sampled points set\n",
    "D1 = vertice_distance_init(vertices,faces)\n",
    "n_vertices = vertices.shape[0]\n",
    "D2 = np.array(np.nan)\n",
    "while len(D2.shape)==0:\n",
    "    vertices_add_index = random.sample(range(N_sample),n_vertices)\n",
    "    vertices_new = np.vstack([vertices,P[vertices_add_index]])\n",
    "    for k in range(5,10):\n",
    "        D2 = knn_distance_init(vertices_new,k)\n",
    "        if len(D2.shape) == 2:\n",
    "            break\n",
    "D = D2\n",
    "D[:n_vertices,:n_vertices] = np.reshape(np.min(np.vstack([np.reshape(D1,-1),np.reshape(D2[:n_vertices,:n_vertices],-1)]),0),[n_vertices,n_vertices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-337-1eedf64be11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mneighbor_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex_neighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mclose_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbor_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_neighbor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mneighbor_keep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_neighbor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mneighbor_nodes_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mneighbor_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbor_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Given a initial distance matrix D with inf (meaning no connection)\n",
    "# Return a new distance matrix d by Dijkstra algorithm\n",
    "# Compute the distance by adding the edge length given in D\n",
    "# Just too slow\n",
    "\n",
    "def Dijkstra_distance(D):\n",
    "    N = D.shape[0]\n",
    "    d = np.copy(D)\n",
    "    # for each point i explore the distance\n",
    "    for index_point in range(N):\n",
    "        print(index_point)\n",
    "        close_list = np.zeros(N)\n",
    "        close_list[index_point] = 1\n",
    "        open_list = list(np.where(np.isfinite(d[index_point]))[0])\n",
    "        open_list_distance = list(d[index_point][open_list])\n",
    "        for iters in range(N-1):\n",
    "            # find the node with smallest distance\n",
    "            # name it open_node\n",
    "            # remove from open_list, add to close_list\n",
    "            # print(open_list)\n",
    "            nearest_index = np.argmin(np.array(open_list_distance))\n",
    "            open_node = open_list[nearest_index]\n",
    "            open_list.remove(open_node)\n",
    "            open_list_distance.remove(open_list_distance[nearest_index])\n",
    "            close_list[open_node] = 1\n",
    "            # find the neighbors of open_list\n",
    "            neighbor_nodes = list(np.where(np.isfinite(d[open_node]))[0])\n",
    "            neighbor_nodes.remove(open_node)\n",
    "            # only keep the neighbors that are not in close_list\n",
    "            # actually we should also discard those in open_list\n",
    "            neighbor_keep = []\n",
    "            for index_neighbor in range(len(neighbor_nodes)):\n",
    "                if close_list[neighbor_nodes[index_neighbor]] != 1:\n",
    "                    neighbor_keep.extend([index_neighbor])\n",
    "            neighbor_nodes_keep = [neighbor_nodes[i] for i in neighbor_keep]\n",
    "            for index_neighbor in neighbor_nodes_keep:\n",
    "                if d[index_point][open_node]+d[open_node][index_neighbor] < d[index_point][index_neighbor]:\n",
    "                    d[index_point][index_neighbor] = d[index_point][open_node]+d[open_node][index_neighbor]\n",
    "                    open_list.extend([index_neighbor])\n",
    "                    open_list_distance.extend([d[index_point][index_neighbor]])\n",
    "            if np.sum(close_list) == N:\n",
    "                continue\n",
    "        # connect point[index_point] with all the other points\n",
    "        d[:,index_point] = d[index_point,:]\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Floyd algorithm to build distance matrix\n",
    "def Floyd_distance(D):\n",
    "    N = D.shape[0]\n",
    "    d = np.copy(D)\n",
    "    for index_middle in range(N):\n",
    "        for index_i in range(N):\n",
    "            d[index_i] = np.min(np.vstack([d[index_i],d[index_i][index_middle]+d[index_middle]]),0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Floyd_distance(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('vertices_new_violin_case.pkl', 'wb')\n",
    "pickle.dump(vertices_new, output)\n",
    "output.close()\n",
    "output = open('vertices_new_dist_violin_case.pkl', 'wb')\n",
    "pickle.dump(d, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-395-84305ac52bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvertices_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0md1_smallest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vertice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlocal_vertice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvertices_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0md2_smallest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vertice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlocal_vertice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmin_dist12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2285\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use landmark distance matrix to calculate the whole distance matrix\n",
    "N_sample = P.shape[0]\n",
    "N_vertices_new = vertices_new.shape[0]\n",
    "dist_matrix = np.zeros([N_sample,N_sample])\n",
    "dist_matrix[:] = np.inf\n",
    "local_vertice = 5\n",
    "for index_i in range(N_sample):\n",
    "    dist_matrix[index_i,index_i] = 0\n",
    "    for index_j in range(index_i+1,N_sample):\n",
    "        d1 = np.linalg.norm(P[index_i]-vertices_new,axis=1)\n",
    "        d1_smallest_index = np.argpartition(d1, local_vertice)[:local_vertice]        \n",
    "        d2 = np.linalg.norm(P[index_j]-vertices_new,axis=1)\n",
    "        d2_smallest_index = np.argpartition(d2, local_vertice)[:local_vertice]\n",
    "        min_dist12 = np.inf\n",
    "        for local_i in d1_smallest_index:\n",
    "            for local_j in d2_smallest_index:\n",
    "                if d1[local_i] + d[local_i][local_j] + d2[local_j] < min_dist12:\n",
    "                    min_dist12 = d1[local_i] + d[local_i][local_j] + d2[local_j]      \n",
    "        dist_matrix[index_i][index_j] = min_dist12\n",
    "dist_matrix = np.reshape(np.min(np.vstack([np.reshape(dist_matrix,-1),np.reshape(dist_matrix.T,-1)]),0),[N_sample,N_sample])\n",
    "print(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farthest Point Sampling\n",
    "# Given a point set and a distance matrix\n",
    "# Return a sampled point set\n",
    "# def Farthest_Sampling(P,d,n):\n",
    "d = scipy.spatial.distance.cdist(P,P)\n",
    "# d = pickle.load(open('dist_violin_case_geo.pkl', 'rb'))\n",
    "n = 1000\n",
    "N = P.shape[0]\n",
    "S_index = random.sample(range(N),1)\n",
    "for iters in range(n-1):\n",
    "    min_distance = np.min(d[S_index,],0)\n",
    "    index_max = np.argmax(min_distance)\n",
    "    S_index.extend([index_max])\n",
    "S = P[S_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc34b183828>"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = pd.DataFrame(S, columns=['x', 'y', 'z'])\n",
    "cloud = PyntCloud(points)\n",
    "cloud.plot(point_size = 0.01,lines=[], line_color=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1060, 1060)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pickle.load(open('dist_teapot_new.pkl', 'rb'))\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('violin_case_area.pkl', 'wb')\n",
    "pickle.dump(violin_case_area, output)\n",
    "output.close()\n",
    "output = open('teapot_area.pkl', 'wb')\n",
    "pickle.dump(teapot_area, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
