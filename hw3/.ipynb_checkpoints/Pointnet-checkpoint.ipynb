{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiaojun/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "\"\"\"\n",
    "Helper functions to implement PointNet\n",
    "\"\"\"\n",
    "MODELNET40_PATH = \"modelnet40_ply_hdf5_2048\"\n",
    "h5_filename_train = [\"ply_data_train0.h5\",\"ply_data_train1.h5\",\"ply_data_train2.h5\",\"ply_data_train3.h5\",\"ply_data_train4.h5\"]\n",
    "h5_filename_test = [\"ply_data_test0.h5\",\"ply_data_test1.h5\"]\n",
    "\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    \"\"\"\n",
    "    Data loader function.\n",
    "    Input: The path of h5 filename\n",
    "    Output: A tuple of (data,label)\n",
    "    \"\"\"\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "def get_category_names():\n",
    "    \"\"\"\n",
    "    Function to list out all the categories in MODELNET40\n",
    "    \"\"\"\n",
    "    shape_names_file = os.path.join(MODELNET40_PATH, 'shape_names.txt')\n",
    "    shape_names = [line.rstrip() for line in open(shape_names_file)]\n",
    "    return shape_names\n",
    "\n",
    "def evaluate(true_labels,predicted_labels):\n",
    "    \"\"\"\n",
    "    Function to calculate the total accuracy.\n",
    "    Input: The ground truth labels and the predicted labels\n",
    "    Output: The accuracy of the model\n",
    "    \"\"\"\n",
    "    return np.mean(true_labels == predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0, train_label0 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[0]))\n",
    "train_data1, train_label1 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[1]))\n",
    "train_data2, train_label2 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[2]))\n",
    "train_data3, train_label3 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[3]))\n",
    "train_data4, train_label4 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[4]))\n",
    "train_data = np.concatenate((train_data0, train_data1), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data2), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data3), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data4), axis=0)\n",
    "train_data = train_data[:,:1024,:]\n",
    "train_label = np.concatenate((train_label0, train_label1), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label2), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label3), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label4), axis=0)\n",
    "train_label = np.reshape(train_label,[-1])\n",
    "\n",
    "test_data0, test_label0 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_test[0]))\n",
    "test_data1, test_label1 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_test[1]))\n",
    "test_data = np.concatenate((test_data0, test_data1), axis=0)\n",
    "test_data = test_data[:,:1024,:]\n",
    "test_label = np.concatenate((test_label0, test_label1), axis=0)\n",
    "test_label = np.reshape(test_label,[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True\n",
    "\n",
    "def fully_connected(prev_layer, num_units, batch_norm, is_training=False):\n",
    "    layer = tf.layers.dense(prev_layer, num_units, use_bias=False, activation=None)\n",
    "    if batch_norm:\n",
    "        layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def conv_layer(prev_layer, layer_depth, kernel_size, batch_norm, is_training=False):\n",
    "    strides = [1,1]\n",
    "    conv_layer = tf.layers.conv2d(prev_layer, layer_depth, kernel_size, strides, use_bias=False, activation=None)\n",
    "    if batch_norm:\n",
    "        conv_layer = tf.layers.batch_normalization(conv_layer, training=is_training)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    return conv_layer\n",
    "\n",
    "def dropout_layer(prev_layer, keep_prob, is_training=False):\n",
    "    dropout_layer = tf.cond(is_training,\n",
    "                            lambda: tf.nn.dropout(prev_layer, keep_prob),\n",
    "                            lambda: prev_layer)\n",
    "    return dropout_layer\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 1024, 3])\n",
    "label = tf.placeholder(tf.int32, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "batch_size = X.get_shape()[0].value\n",
    "num_point = X.get_shape()[1].value\n",
    "input_x = tf.expand_dims(X, -1)\n",
    "\n",
    "batch = tf.Variable(0)\n",
    "\n",
    "# MLP implemented as conv2d\n",
    "conv_layer1 = conv_layer(input_x, 64, [1,3], batch_norm, is_training)\n",
    "conv_layer2 = conv_layer(conv_layer1, 64, [1,1], batch_norm, is_training)\n",
    "conv_layer3 = conv_layer(conv_layer2, 64, [1,1], batch_norm, is_training)\n",
    "conv_layer4 = conv_layer(conv_layer3, 128, [1,1], batch_norm, is_training)\n",
    "conv_layer5 = conv_layer(conv_layer4, 1024, [1,1], batch_norm, is_training)\n",
    "# Maxpooling\n",
    "maxpool_layer = tf.nn.max_pool(conv_layer5, ksize=[1,num_point,1,1], strides=[1,2,2,1], padding='VALID')\n",
    "global_layer = tf.reshape(maxpool_layer, [-1,1024])\n",
    "# MLP implemented as fully-connected\n",
    "fc_layer1 = fully_connected(global_layer, 512, batch_norm, is_training)\n",
    "fc_layer2 = fully_connected(fc_layer1, 256, batch_norm, is_training)\n",
    "# Dropout\n",
    "dropout_layer = dropout_layer(fc_layer2, 0.7, is_training)\n",
    "output = fully_connected(dropout_layer, 40, batch_norm, is_training)\n",
    "\n",
    "# loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=label)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# accuracy\n",
    "predict = tf.cast(tf.argmax(output,1),tf.int32)\n",
    "correct_prediction = tf.equal(predict,label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# optimize\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "#model_train = optimizer.minimize(loss, global_step=batch)\n",
    "model_train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 1024, 3)\n",
      "(9840,)\n",
      "(2468, 1024, 3)\n",
      "(2468,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "batch_num = np.ceil(num_train/batch_size).astype(int)\n",
    "print(batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  3,  5, 26, 37, 35, 30, 34, 16, 20, 31,  0,  1, 22,  9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(oout,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:  0  batch_idx:  0 \tloss: 3.6871 \taccuracy: 0.0625\n",
      "TRAIN: epoch:  0  batch_idx:  100 \tloss: 3.6696 \taccuracy: 0.0312\n",
      "TRAIN: epoch:  0  batch_idx:  200 \tloss: 3.6625 \taccuracy: 0.0625\n",
      "TRAIN: epoch:  0  batch_idx:  300 \tloss: 3.6619 \taccuracy: 0.0000\n",
      "VALID: epoch:  0 \tloss: 0.3797 \taccuracy: 0.0028\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_point = 1024\n",
    "learning_rate = 0.001\n",
    "batch_norm = True\n",
    "max_epoch = 100\n",
    "\n",
    "num_train = train_label.shape[0]\n",
    "num_test = test_label.shape[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    batch_num = np.ceil(num_train/batch_size).astype(int)\n",
    "    batch_num_test = np.ceil(num_test/batch_size/10).astype(int)\n",
    "    for epoch in range(1):\n",
    "        # shuffle the data for each epoch\n",
    "        idx = np.arange(num_train)\n",
    "        np.random.shuffle(idx)\n",
    "        train_data = train_data[idx, ...]\n",
    "        train_label = train_label[idx]\n",
    "        for batch_idx in range(batch_num):\n",
    "            start_idx = batch_idx*batch_size\n",
    "            end_idx = np.min([(batch_idx+1)*batch_size,num_train-1])\n",
    "            sess.run([model_train],{X: train_data[start_idx:end_idx,...], \\\n",
    "                                    label: train_label[start_idx:end_idx], is_training: True})\n",
    "            oout,ppred,ccorrect,aaccu = sess.run([output,predict,correct_prediction,accuracy], \\\n",
    "                                        {X: train_data[start_idx:end_idx,...], \\\n",
    "                                         label: train_label[start_idx:end_idx], is_training: True})\n",
    "            \n",
    "            \n",
    "            loss_val,acc_val = sess.run([loss,accuracy], \\\n",
    "                                        {X: train_data[start_idx:end_idx,...], \\\n",
    "                                         label: train_label[start_idx:end_idx], is_training: False})\n",
    "            if batch_idx%100 == 0:\n",
    "                print('TRAIN: epoch: ', epoch, ' batch_idx: ', batch_idx, '\\tloss: %.4f'%loss_val, '\\taccuracy: %.4f'%acc_val)\n",
    "        # validation\n",
    "        loss_val_all = 0\n",
    "        acc_val_all = 0\n",
    "        for batch_idx in range(batch_num_test):\n",
    "            start_idx = batch_idx*batch_size\n",
    "            end_idx = np.min([(batch_idx+1)*batch_size,num_test-1])\n",
    "            loss_val,acc_val = sess.run([loss,accuracy], \\\n",
    "                                        {X: test_data[start_idx:end_idx,...], \\\n",
    "                                         label: test_label[start_idx:end_idx], is_training: False})\n",
    "            loss_val_all = loss_val_all + loss_val*(end_idx-start_idx)\n",
    "            acc_val_all = acc_val_all + acc_val*(end_idx-start_idx) \n",
    "        loss_val_all = loss_val_all / num_test\n",
    "        acc_val_all = acc_val_all / num_test\n",
    "        print('VALID: epoch: ', epoch, '\\tloss: %.4f'%loss_val_all, '\\taccuracy: %.4f'%acc_val_all)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
