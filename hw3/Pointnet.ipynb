{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiaojun/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "\"\"\"\n",
    "Helper functions to implement PointNet\n",
    "\"\"\"\n",
    "MODELNET40_PATH = \"modelnet40_ply_hdf5_2048\"\n",
    "h5_filename_train = [\"ply_data_train0.h5\",\"ply_data_train1.h5\",\"ply_data_train2.h5\",\"ply_data_train3.h5\",\"ply_data_train4.h5\"]\n",
    "h5_filename_test = [\"ply_data_test0.h5\",\"ply_data_test1.h5\"]\n",
    "\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    \"\"\"\n",
    "    Data loader function.\n",
    "    Input: The path of h5 filename\n",
    "    Output: A tuple of (data,label)\n",
    "    \"\"\"\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "def get_category_names():\n",
    "    \"\"\"\n",
    "    Function to list out all the categories in MODELNET40\n",
    "    \"\"\"\n",
    "    shape_names_file = os.path.join(MODELNET40_PATH, 'shape_names.txt')\n",
    "    shape_names = [line.rstrip() for line in open(shape_names_file)]\n",
    "    return shape_names\n",
    "\n",
    "def evaluate(true_labels,predicted_labels):\n",
    "    \"\"\"\n",
    "    Function to calculate the total accuracy.\n",
    "    Input: The ground truth labels and the predicted labels\n",
    "    Output: The accuracy of the model\n",
    "    \"\"\"\n",
    "    return np.mean(true_labels == predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0, train_label0 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[0]))\n",
    "train_data1, train_label1 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[1]))\n",
    "train_data2, train_label2 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[2]))\n",
    "train_data3, train_label3 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[3]))\n",
    "train_data4, train_label4 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_train[4]))\n",
    "train_data = np.concatenate((train_data0, train_data1), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data2), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data3), axis=0)\n",
    "train_data = np.concatenate((train_data, train_data4), axis=0)\n",
    "train_data = train_data[:,:1024,:]\n",
    "train_label = np.concatenate((train_label0, train_label1), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label2), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label3), axis=0)\n",
    "train_label = np.concatenate((train_label, train_label4), axis=0)\n",
    "train_label = np.reshape(train_label,[-1])\n",
    "\n",
    "test_data0, test_label0 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_test[0]))\n",
    "test_data1, test_label1 = load_h5(os.path.join(MODELNET40_PATH, h5_filename_test[1]))\n",
    "test_data = np.concatenate((test_data0, test_data1), axis=0)\n",
    "test_data = test_data[:,:1024,:]\n",
    "test_label = np.concatenate((test_label0, test_label1), axis=0)\n",
    "test_label = np.reshape(test_label,[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                        0.001,       # Base learning rate.\n",
    "                        batch * 32,  # Current index into the dataset.\n",
    "                        200000,      # Decay step.\n",
    "                        0.7,        # Decay rate.\n",
    "                        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n",
    "    return learning_rate        \n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.train.exponential_decay(\n",
    "                      0.5,\n",
    "                      batch*32,\n",
    "                      200000,\n",
    "                      0.5,\n",
    "                      staircase=True)\n",
    "    bn_decay = tf.minimum(0.99, 1 - bn_momentum)\n",
    "    return bn_decay\n",
    "\n",
    "def fully_connected(prev_layer, num_units, batch_norm, batch_norm_decay, scope, is_training=False):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        layer = tf.layers.dense(prev_layer, num_units, use_bias=False, activation=None)\n",
    "        if batch_norm:\n",
    "            layer = tf.layers.batch_normalization(layer, momentum=batch_norm_decay, training=is_training)\n",
    "        layer = tf.nn.relu(layer)\n",
    "        return layer\n",
    "\n",
    "def conv_layer(prev_layer, layer_depth, kernel_size, batch_norm, batch_norm_decay, scope, is_training=False):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        strides = [1,1]\n",
    "        conv_layer = tf.layers.conv2d(prev_layer, layer_depth, kernel_size, strides, use_bias=False, activation=None)\n",
    "        if batch_norm:\n",
    "            conv_layer = tf.layers.batch_normalization(conv_layer, momentum=batch_norm_decay, training=is_training)\n",
    "        conv_layer = tf.nn.relu(conv_layer)\n",
    "        return conv_layer\n",
    "\n",
    "def dropout_layer(prev_layer, keep_prob, scope, is_training=False):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        dropout_layer = tf.cond(is_training,\n",
    "                                lambda: tf.nn.dropout(prev_layer, keep_prob),\n",
    "                                lambda: prev_layer)\n",
    "        return dropout_layer\n",
    "\n",
    "def input_transform_net(point_cloud, is_training, bn_decay=None, K=3):\n",
    "    batch_size = point_cloud.get_shape()[0].value\n",
    "    num_point = point_cloud.get_shape()[1].value\n",
    "    input_image = tf.expand_dims(point_cloud, -1)\n",
    "    net = conv_layer(input_image, 64, [1,3], scope='t1_conv_layer1', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = conv_layer(net, 128, [1,1], scope='t1_conv_layer2', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = conv_layer(net, 1024, [1,1], scope='t1_conv_layer3', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = tf.nn.max_pool(net, ksize=[1,num_point,1,1], strides=[1,2,2,1], padding='VALID')\n",
    "    net = tf.reshape(net, [-1,1024])\n",
    "    net = fully_connected(net, 512, scope='t1_fc_layer1', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = fully_connected(net, 256, scope='t1_final_layer', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "\n",
    "    with tf.variable_scope('transform_XYZ') as sc:\n",
    "        assert(K==3)\n",
    "        weights = tf.get_variable('t1_weights', [256, 3*K],\n",
    "                                  initializer=tf.constant_initializer(0.0),\n",
    "                                  dtype=tf.float32)\n",
    "        biases = tf.get_variable('t1_biases', [3*K],\n",
    "                                 initializer=tf.constant_initializer(0.0),\n",
    "                                 dtype=tf.float32)\n",
    "        biases += tf.constant([1,0,0,0,1,0,0,0,1], dtype=tf.float32)\n",
    "        transform = tf.matmul(net, weights)\n",
    "        transform = tf.nn.bias_add(transform, biases)\n",
    "\n",
    "    transform = tf.reshape(transform, [-1, 3, K])\n",
    "    return transform\n",
    "\n",
    "\n",
    "def feature_transform_net(inputs, is_training, bn_decay=None, K=64):\n",
    "    batch_size = inputs.get_shape()[0].value\n",
    "    num_point = inputs.get_shape()[1].value\n",
    "    \n",
    "    net = conv_layer(inputs, 64, [1,1], scope='t2_conv_layer1', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = conv_layer(net, 128, [1,1], scope='t2_conv_layer2', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = conv_layer(net, 1024, [1,1], scope='t2_conv_layer3', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = tf.nn.max_pool(net, ksize=[1,num_point,1,1], strides=[1,2,2,1], padding='VALID')\n",
    "    net = tf.reshape(net, [-1,1024])\n",
    "    net = fully_connected(net, 512, scope='t2_fc_layer1', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "    net = fully_connected(net, 256, scope='t2_final_layer', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "\n",
    "    with tf.variable_scope('transform_feat') as sc:\n",
    "        weights = tf.get_variable('weights', [256, K*K],\n",
    "                                  initializer=tf.constant_initializer(0.0),\n",
    "                                  dtype=tf.float32)\n",
    "        biases = tf.get_variable('biases', [K*K],\n",
    "                                 initializer=tf.constant_initializer(0.0),\n",
    "                                 dtype=tf.float32)\n",
    "        biases += tf.constant(np.eye(K).flatten(), dtype=tf.float32)\n",
    "        transform = tf.matmul(net, weights)\n",
    "        transform = tf.nn.bias_add(transform, biases)\n",
    "\n",
    "    transform = tf.reshape(transform, [-1, K, K])\n",
    "    return transform\n",
    "\n",
    "\n",
    "batch = tf.Variable(0)\n",
    "end_points = {}\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 1024, 3])\n",
    "label = tf.placeholder(tf.int32, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "batch_size = X.get_shape()[0].value\n",
    "num_point = X.get_shape()[1].value\n",
    "\n",
    "bn_decay = get_bn_decay(batch)\n",
    "tf.summary.scalar('bn_decay', bn_decay)\n",
    "\n",
    "#input_x = tf.expand_dims(X, -1)\n",
    "# input transform layer\n",
    "transform = input_transform_net(X, is_training, bn_decay, K=3)\n",
    "X_new = tf.matmul(X, transform)\n",
    "input_x = tf.expand_dims(X_new, -1)\n",
    "\n",
    "# MLP implemented as conv2d\n",
    "conv_layer1 = conv_layer(input_x, 64, [1,3], scope='conv_layer1', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "conv_layer2 = conv_layer(conv_layer1, 64, [1,1], scope='conv_layer2', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "\n",
    "#net_transformed = conv_layer2\n",
    "# feature transform layer\n",
    "with tf.variable_scope('transform_net2') as sc:\n",
    "    transform = feature_transform_net(conv_layer2, is_training, bn_decay, K=64)\n",
    "end_points['transform'] = transform\n",
    "net_transformed = tf.matmul(tf.squeeze(conv_layer2, axis=[2]), transform)\n",
    "net_transformed = tf.expand_dims(net_transformed, [2])\n",
    "\n",
    "# MLP implemented as conv2d\n",
    "conv_layer3 = conv_layer(net_transformed, 64, [1,1], scope='conv_layer3', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "conv_layer4 = conv_layer(conv_layer3, 128, [1,1], scope='conv_layer4', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "conv_layer5 = conv_layer(conv_layer4, 1024, [1,1], scope='conv_layer5', batch_norm=True, batch_norm_decay=bn_decay, is_training=is_training)\n",
    "# Maxpooling\n",
    "maxpool_layer = tf.nn.max_pool(conv_layer5, ksize=[1,num_point,1,1], strides=[1,2,2,1], padding='VALID')\n",
    "global_layer = tf.reshape(maxpool_layer, [-1,1024])\n",
    "# MLP implemented as fully-connected\n",
    "fc_layer1 = fully_connected(global_layer, 512, batch_norm=True, scope='fc_layer1', batch_norm_decay=bn_decay, is_training=is_training)\n",
    "fc_layer2 = fully_connected(fc_layer1, 256, batch_norm=True, scope='fc_layer2', batch_norm_decay=bn_decay, is_training=is_training)\n",
    "# Dropout\n",
    "dropout_layer = dropout_layer(fc_layer2, 0.7, scope = 'dropout', is_training=is_training,)\n",
    "output = fully_connected(dropout_layer, 40, batch_norm=True, scope = 'fc_output', batch_norm_decay=bn_decay, is_training=is_training)\n",
    "\n",
    "# loss\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=label)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "# feature transform regularization loss\n",
    "transform = end_points['transform'] # BxKxK\n",
    "K = transform.get_shape()[1].value\n",
    "mat_diff = tf.matmul(transform, tf.transpose(transform, perm=[0,2,1]))\n",
    "mat_diff -= tf.constant(np.eye(K), dtype=tf.float32)\n",
    "mat_diff_loss = tf.nn.l2_loss(mat_diff) \n",
    "loss = loss + mat_diff_loss * 0.001\n",
    "\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "# accuracy\n",
    "predict = tf.cast(tf.argmax(output,1),tf.int32)\n",
    "correct_prediction = tf.equal(predict,label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# optimize\n",
    "learning_rate = get_learning_rate(batch)\n",
    "tf.summary.scalar('learning_rate', learning_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    model_train = optimizer.minimize(loss, global_step=batch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_pointcloud(pc):\n",
    "    # input pc should be a B*P*3 matrix\n",
    "    # B for batch_size, N for point_size\n",
    "    # output with same shape\n",
    "    pc_new = np.copy(pc)\n",
    "    for b in range(pc.shape[0]):\n",
    "        angle_x = np.random.uniform() * 2 * np.pi\n",
    "        angle_y = np.random.uniform() * 2 * np.pi\n",
    "        angle_z = np.random.uniform() * 2 * np.pi\n",
    "        matrix_x = np.array([[1,0,0],[0,np.cos(angle_x),-np.sin(angle_x)],[0,np.sin(angle_x),np.cos(angle_x)]])\n",
    "        matrix_y = np.array([[np.cos(angle_y),0,np.sin(angle_y)],[0,1,0],[-np.sin(angle_y),0,np.cos(angle_y)]])\n",
    "        matrix_z = np.array([[np.cos(angle_z),-np.sin(angle_z),0],[np.sin(angle_z),np.cos(angle_z),0],[0,0,1]])\n",
    "        #pc[b] = np.dot(np.dot(np.dot(np.reshape(pc[b],[-1,3]),matrix_x),matrix_y),matrix_z)\n",
    "        #pc[b] = np.dot(np.dot(np.reshape(pc[b],[-1,3]),matrix_x),matrix_y)\n",
    "        pc_new[b] = np.dot(np.reshape(pc[b],[-1,3]),matrix_y)   \n",
    "    return pc_new\n",
    "    \n",
    "def jittering_pointcloud(pc,sigma = 0.01,clip=0.05):\n",
    "    pc_new = np.copy(pc)\n",
    "    B, P, C = pc.shape\n",
    "    jitter = np.clip(sigma * np.random.randn(B, P, C), -1*clip, clip)\n",
    "    pc_new = pc + jitter\n",
    "    return pc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:  1 \tloss: 3.1937 \taccuracy: 0.4277\n",
      "VALID: epoch:  1 \tloss: 1.9505 \ttotal accuracy: 0.5032 \t per class accuracy: 0.4349\n",
      "TRAIN: epoch:  2 \tloss: 1.4897 \taccuracy: 0.6610\n",
      "VALID: epoch:  2 \tloss: 1.5373 \ttotal accuracy: 0.5900 \t per class accuracy: 0.5236\n",
      "TRAIN: epoch:  3 \tloss: 1.1168 \taccuracy: 0.7386\n",
      "VALID: epoch:  3 \tloss: 1.1998 \ttotal accuracy: 0.6811 \t per class accuracy: 0.6021\n",
      "TRAIN: epoch:  4 \tloss: 0.9929 \taccuracy: 0.7555\n",
      "VALID: epoch:  4 \tloss: 1.1238 \ttotal accuracy: 0.6961 \t per class accuracy: 0.6292\n",
      "TRAIN: epoch:  5 \tloss: 0.8554 \taccuracy: 0.7850\n",
      "VALID: epoch:  5 \tloss: 1.1654 \ttotal accuracy: 0.6945 \t per class accuracy: 0.6327\n",
      "TRAIN: epoch:  6 \tloss: 1.0339 \taccuracy: 0.7342\n",
      "VALID: epoch:  6 \tloss: 1.1362 \ttotal accuracy: 0.6892 \t per class accuracy: 0.6130\n",
      "TRAIN: epoch:  7 \tloss: 0.7958 \taccuracy: 0.7911\n",
      "VALID: epoch:  7 \tloss: 0.9447 \ttotal accuracy: 0.7630 \t per class accuracy: 0.6944\n",
      "TRAIN: epoch:  8 \tloss: 0.7198 \taccuracy: 0.8086\n",
      "VALID: epoch:  8 \tloss: 1.0307 \ttotal accuracy: 0.7399 \t per class accuracy: 0.6880\n",
      "TRAIN: epoch:  9 \tloss: 0.6725 \taccuracy: 0.8211\n",
      "VALID: epoch:  9 \tloss: 0.9901 \ttotal accuracy: 0.7338 \t per class accuracy: 0.6886\n",
      "TRAIN: epoch:  10 \tloss: 0.6363 \taccuracy: 0.8263\n",
      "VALID: epoch:  10 \tloss: 1.0853 \ttotal accuracy: 0.7083 \t per class accuracy: 0.6763\n",
      "TRAIN: epoch:  11 \tloss: 0.5948 \taccuracy: 0.8379\n",
      "VALID: epoch:  11 \tloss: 0.8624 \ttotal accuracy: 0.7848 \t per class accuracy: 0.7044\n",
      "TRAIN: epoch:  12 \tloss: 0.5604 \taccuracy: 0.8427\n",
      "VALID: epoch:  12 \tloss: 1.2481 \ttotal accuracy: 0.6965 \t per class accuracy: 0.6382\n",
      "TRAIN: epoch:  13 \tloss: 0.5492 \taccuracy: 0.8477\n",
      "VALID: epoch:  13 \tloss: 0.8430 \ttotal accuracy: 0.7703 \t per class accuracy: 0.7202\n",
      "TRAIN: epoch:  14 \tloss: 0.5422 \taccuracy: 0.8514\n",
      "VALID: epoch:  14 \tloss: 0.7938 \ttotal accuracy: 0.7889 \t per class accuracy: 0.7486\n",
      "TRAIN: epoch:  15 \tloss: 0.5144 \taccuracy: 0.8582\n",
      "VALID: epoch:  15 \tloss: 0.7849 \ttotal accuracy: 0.7877 \t per class accuracy: 0.7476\n",
      "TRAIN: epoch:  16 \tloss: 0.5156 \taccuracy: 0.8550\n",
      "VALID: epoch:  16 \tloss: 0.8212 \ttotal accuracy: 0.7836 \t per class accuracy: 0.7581\n",
      "TRAIN: epoch:  17 \tloss: 0.5248 \taccuracy: 0.8557\n",
      "VALID: epoch:  17 \tloss: 0.7730 \ttotal accuracy: 0.8011 \t per class accuracy: 0.7606\n",
      "TRAIN: epoch:  18 \tloss: 0.4822 \taccuracy: 0.8616\n",
      "VALID: epoch:  18 \tloss: 0.7451 \ttotal accuracy: 0.7998 \t per class accuracy: 0.7576\n",
      "TRAIN: epoch:  19 \tloss: 0.4628 \taccuracy: 0.8698\n",
      "VALID: epoch:  19 \tloss: 0.7341 \ttotal accuracy: 0.8075 \t per class accuracy: 0.7445\n",
      "TRAIN: epoch:  20 \tloss: 0.4462 \taccuracy: 0.8700\n",
      "VALID: epoch:  20 \tloss: 0.7099 \ttotal accuracy: 0.8059 \t per class accuracy: 0.7654\n",
      "TRAIN: epoch:  21 \tloss: 0.4028 \taccuracy: 0.8831\n",
      "VALID: epoch:  21 \tloss: 0.5658 \ttotal accuracy: 0.8448 \t per class accuracy: 0.8089\n",
      "TRAIN: epoch:  22 \tloss: 0.3831 \taccuracy: 0.8893\n",
      "VALID: epoch:  22 \tloss: 0.6939 \ttotal accuracy: 0.8063 \t per class accuracy: 0.7701\n",
      "TRAIN: epoch:  23 \tloss: 0.3713 \taccuracy: 0.8888\n",
      "VALID: epoch:  23 \tloss: 0.5547 \ttotal accuracy: 0.8509 \t per class accuracy: 0.8017\n",
      "TRAIN: epoch:  24 \tloss: 0.3599 \taccuracy: 0.8945\n",
      "VALID: epoch:  24 \tloss: 0.6381 \ttotal accuracy: 0.8294 \t per class accuracy: 0.8030\n",
      "TRAIN: epoch:  25 \tloss: 0.3628 \taccuracy: 0.8936\n",
      "VALID: epoch:  25 \tloss: 0.6080 \ttotal accuracy: 0.8327 \t per class accuracy: 0.7861\n",
      "TRAIN: epoch:  26 \tloss: 0.3497 \taccuracy: 0.8964\n",
      "VALID: epoch:  26 \tloss: 0.6298 \ttotal accuracy: 0.8246 \t per class accuracy: 0.7924\n",
      "TRAIN: epoch:  27 \tloss: 0.3374 \taccuracy: 0.9004\n",
      "VALID: epoch:  27 \tloss: 0.5638 \ttotal accuracy: 0.8440 \t per class accuracy: 0.8149\n",
      "TRAIN: epoch:  28 \tloss: 0.3397 \taccuracy: 0.8981\n",
      "VALID: epoch:  28 \tloss: 0.5602 \ttotal accuracy: 0.8509 \t per class accuracy: 0.8107\n",
      "TRAIN: epoch:  29 \tloss: 0.3238 \taccuracy: 0.9042\n",
      "VALID: epoch:  29 \tloss: 0.5389 \ttotal accuracy: 0.8505 \t per class accuracy: 0.8215\n",
      "TRAIN: epoch:  30 \tloss: 0.3192 \taccuracy: 0.9041\n",
      "VALID: epoch:  30 \tloss: 0.5543 \ttotal accuracy: 0.8452 \t per class accuracy: 0.8106\n",
      "TRAIN: epoch:  31 \tloss: 0.3309 \taccuracy: 0.9020\n",
      "VALID: epoch:  31 \tloss: 0.5705 \ttotal accuracy: 0.8464 \t per class accuracy: 0.7947\n",
      "TRAIN: epoch:  32 \tloss: 0.3182 \taccuracy: 0.9062\n",
      "VALID: epoch:  32 \tloss: 0.5546 \ttotal accuracy: 0.8408 \t per class accuracy: 0.8149\n",
      "TRAIN: epoch:  33 \tloss: 0.3023 \taccuracy: 0.9102\n",
      "VALID: epoch:  33 \tloss: 0.6016 \ttotal accuracy: 0.8282 \t per class accuracy: 0.7967\n",
      "TRAIN: epoch:  34 \tloss: 0.2983 \taccuracy: 0.9082\n",
      "VALID: epoch:  34 \tloss: 0.5819 \ttotal accuracy: 0.8428 \t per class accuracy: 0.8232\n",
      "TRAIN: epoch:  35 \tloss: 0.2955 \taccuracy: 0.9108\n",
      "VALID: epoch:  35 \tloss: 0.5997 \ttotal accuracy: 0.8327 \t per class accuracy: 0.8078\n",
      "TRAIN: epoch:  36 \tloss: 0.2922 \taccuracy: 0.9137\n",
      "VALID: epoch:  36 \tloss: 0.7031 \ttotal accuracy: 0.8108 \t per class accuracy: 0.7791\n",
      "TRAIN: epoch:  37 \tloss: 0.4442 \taccuracy: 0.8655\n",
      "VALID: epoch:  37 \tloss: 0.5559 \ttotal accuracy: 0.8452 \t per class accuracy: 0.8083\n",
      "TRAIN: epoch:  38 \tloss: 0.3138 \taccuracy: 0.9013\n",
      "VALID: epoch:  38 \tloss: 0.5660 \ttotal accuracy: 0.8464 \t per class accuracy: 0.8162\n",
      "TRAIN: epoch:  39 \tloss: 0.3550 \taccuracy: 0.8975\n",
      "VALID: epoch:  39 \tloss: 2.8415 \ttotal accuracy: 0.4457 \t per class accuracy: 0.4127\n",
      "TRAIN: epoch:  40 \tloss: 0.6229 \taccuracy: 0.8206\n",
      "VALID: epoch:  40 \tloss: 0.7323 \ttotal accuracy: 0.7909 \t per class accuracy: 0.7571\n",
      "TRAIN: epoch:  41 \tloss: 0.4195 \taccuracy: 0.8715\n",
      "VALID: epoch:  41 \tloss: 0.5929 \ttotal accuracy: 0.8213 \t per class accuracy: 0.7820\n",
      "TRAIN: epoch:  42 \tloss: 0.3602 \taccuracy: 0.8864\n",
      "VALID: epoch:  42 \tloss: 0.5852 \ttotal accuracy: 0.8456 \t per class accuracy: 0.8092\n",
      "TRAIN: epoch:  43 \tloss: 0.3432 \taccuracy: 0.8899\n",
      "VALID: epoch:  43 \tloss: 0.5549 \ttotal accuracy: 0.8379 \t per class accuracy: 0.8046\n",
      "TRAIN: epoch:  44 \tloss: 0.3439 \taccuracy: 0.8935\n",
      "VALID: epoch:  44 \tloss: 0.5186 \ttotal accuracy: 0.8553 \t per class accuracy: 0.8167\n",
      "TRAIN: epoch:  45 \tloss: 0.3135 \taccuracy: 0.9014\n",
      "VALID: epoch:  45 \tloss: 0.5456 \ttotal accuracy: 0.8412 \t per class accuracy: 0.8073\n",
      "TRAIN: epoch:  46 \tloss: 0.2927 \taccuracy: 0.9098\n",
      "VALID: epoch:  46 \tloss: 0.5302 \ttotal accuracy: 0.8525 \t per class accuracy: 0.8164\n",
      "TRAIN: epoch:  47 \tloss: 0.2784 \taccuracy: 0.9148\n",
      "VALID: epoch:  47 \tloss: 0.5411 \ttotal accuracy: 0.8412 \t per class accuracy: 0.8045\n",
      "TRAIN: epoch:  48 \tloss: 0.2781 \taccuracy: 0.9125\n",
      "VALID: epoch:  48 \tloss: 0.4947 \ttotal accuracy: 0.8606 \t per class accuracy: 0.8285\n",
      "TRAIN: epoch:  49 \tloss: 0.2702 \taccuracy: 0.9127\n",
      "VALID: epoch:  49 \tloss: 0.5229 \ttotal accuracy: 0.8598 \t per class accuracy: 0.8317\n",
      "TRAIN: epoch:  50 \tloss: 0.2565 \taccuracy: 0.9207\n",
      "Model saved in file: log_2/model_50.ckpt\n",
      "VALID: epoch:  50 \tloss: 0.5183 \ttotal accuracy: 0.8574 \t per class accuracy: 0.8203\n",
      "TRAIN: epoch:  51 \tloss: 0.2578 \taccuracy: 0.9214\n",
      "VALID: epoch:  51 \tloss: 0.5073 \ttotal accuracy: 0.8574 \t per class accuracy: 0.8301\n",
      "TRAIN: epoch:  52 \tloss: 0.2457 \taccuracy: 0.9220\n",
      "VALID: epoch:  52 \tloss: 0.5464 \ttotal accuracy: 0.8558 \t per class accuracy: 0.8271\n",
      "TRAIN: epoch:  53 \tloss: 0.2415 \taccuracy: 0.9258\n",
      "VALID: epoch:  53 \tloss: 0.5389 \ttotal accuracy: 0.8562 \t per class accuracy: 0.8290\n",
      "TRAIN: epoch:  54 \tloss: 0.2383 \taccuracy: 0.9241\n",
      "VALID: epoch:  54 \tloss: 0.4838 \ttotal accuracy: 0.8703 \t per class accuracy: 0.8374\n",
      "TRAIN: epoch:  55 \tloss: 0.2287 \taccuracy: 0.9285\n",
      "VALID: epoch:  55 \tloss: 0.5137 \ttotal accuracy: 0.8549 \t per class accuracy: 0.8288\n",
      "TRAIN: epoch:  56 \tloss: 0.2199 \taccuracy: 0.9306\n",
      "VALID: epoch:  56 \tloss: 0.4962 \ttotal accuracy: 0.8614 \t per class accuracy: 0.8305\n",
      "TRAIN: epoch:  57 \tloss: 0.2281 \taccuracy: 0.9263\n",
      "VALID: epoch:  57 \tloss: 0.4835 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8535\n",
      "TRAIN: epoch:  58 \tloss: 0.2199 \taccuracy: 0.9303\n",
      "VALID: epoch:  58 \tloss: 0.4898 \ttotal accuracy: 0.8679 \t per class accuracy: 0.8356\n",
      "TRAIN: epoch:  59 \tloss: 0.2113 \taccuracy: 0.9345\n",
      "VALID: epoch:  59 \tloss: 0.5069 \ttotal accuracy: 0.8586 \t per class accuracy: 0.8259\n",
      "TRAIN: epoch:  60 \tloss: 0.2075 \taccuracy: 0.9360\n",
      "VALID: epoch:  60 \tloss: 0.5155 \ttotal accuracy: 0.8622 \t per class accuracy: 0.8302\n",
      "TRAIN: epoch:  61 \tloss: 0.2640 \taccuracy: 0.9205\n",
      "VALID: epoch:  61 \tloss: 0.5426 \ttotal accuracy: 0.8485 \t per class accuracy: 0.8187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:  62 \tloss: 0.2401 \taccuracy: 0.9241\n",
      "VALID: epoch:  62 \tloss: 0.4971 \ttotal accuracy: 0.8578 \t per class accuracy: 0.8369\n",
      "TRAIN: epoch:  63 \tloss: 0.2052 \taccuracy: 0.9354\n",
      "VALID: epoch:  63 \tloss: 0.4605 \ttotal accuracy: 0.8724 \t per class accuracy: 0.8424\n",
      "TRAIN: epoch:  64 \tloss: 0.1956 \taccuracy: 0.9381\n",
      "VALID: epoch:  64 \tloss: 0.5027 \ttotal accuracy: 0.8586 \t per class accuracy: 0.8248\n",
      "TRAIN: epoch:  65 \tloss: 0.1884 \taccuracy: 0.9409\n",
      "VALID: epoch:  65 \tloss: 0.4824 \ttotal accuracy: 0.8699 \t per class accuracy: 0.8401\n",
      "TRAIN: epoch:  66 \tloss: 0.1856 \taccuracy: 0.9422\n",
      "VALID: epoch:  66 \tloss: 0.4924 \ttotal accuracy: 0.8695 \t per class accuracy: 0.8477\n",
      "TRAIN: epoch:  67 \tloss: 0.1787 \taccuracy: 0.9434\n",
      "VALID: epoch:  67 \tloss: 0.4794 \ttotal accuracy: 0.8756 \t per class accuracy: 0.8464\n",
      "TRAIN: epoch:  68 \tloss: 0.1763 \taccuracy: 0.9453\n",
      "VALID: epoch:  68 \tloss: 0.4884 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8434\n",
      "TRAIN: epoch:  69 \tloss: 0.1747 \taccuracy: 0.9447\n",
      "VALID: epoch:  69 \tloss: 0.4947 \ttotal accuracy: 0.8663 \t per class accuracy: 0.8354\n",
      "TRAIN: epoch:  70 \tloss: 0.1696 \taccuracy: 0.9458\n",
      "VALID: epoch:  70 \tloss: 0.4926 \ttotal accuracy: 0.8659 \t per class accuracy: 0.8394\n",
      "TRAIN: epoch:  71 \tloss: 0.1767 \taccuracy: 0.9441\n",
      "VALID: epoch:  71 \tloss: 0.4817 \ttotal accuracy: 0.8618 \t per class accuracy: 0.8308\n",
      "TRAIN: epoch:  72 \tloss: 0.1724 \taccuracy: 0.9453\n",
      "VALID: epoch:  72 \tloss: 0.5141 \ttotal accuracy: 0.8586 \t per class accuracy: 0.8386\n",
      "TRAIN: epoch:  73 \tloss: 0.1657 \taccuracy: 0.9474\n",
      "VALID: epoch:  73 \tloss: 0.4631 \ttotal accuracy: 0.8784 \t per class accuracy: 0.8494\n",
      "TRAIN: epoch:  74 \tloss: 0.1582 \taccuracy: 0.9470\n",
      "VALID: epoch:  74 \tloss: 0.4805 \ttotal accuracy: 0.8716 \t per class accuracy: 0.8453\n",
      "TRAIN: epoch:  75 \tloss: 0.1622 \taccuracy: 0.9483\n",
      "VALID: epoch:  75 \tloss: 0.5151 \ttotal accuracy: 0.8558 \t per class accuracy: 0.8198\n",
      "TRAIN: epoch:  76 \tloss: 0.1585 \taccuracy: 0.9486\n",
      "VALID: epoch:  76 \tloss: 0.4912 \ttotal accuracy: 0.8635 \t per class accuracy: 0.8398\n",
      "TRAIN: epoch:  77 \tloss: 0.1610 \taccuracy: 0.9482\n",
      "VALID: epoch:  77 \tloss: 0.5290 \ttotal accuracy: 0.8695 \t per class accuracy: 0.8477\n",
      "TRAIN: epoch:  78 \tloss: 0.1525 \taccuracy: 0.9500\n",
      "VALID: epoch:  78 \tloss: 0.4807 \ttotal accuracy: 0.8724 \t per class accuracy: 0.8469\n",
      "TRAIN: epoch:  79 \tloss: 0.1479 \taccuracy: 0.9527\n",
      "VALID: epoch:  79 \tloss: 0.5069 \ttotal accuracy: 0.8586 \t per class accuracy: 0.8287\n",
      "TRAIN: epoch:  80 \tloss: 0.1529 \taccuracy: 0.9509\n",
      "VALID: epoch:  80 \tloss: 0.4797 \ttotal accuracy: 0.8679 \t per class accuracy: 0.8426\n",
      "TRAIN: epoch:  81 \tloss: 0.1451 \taccuracy: 0.9529\n",
      "VALID: epoch:  81 \tloss: 0.4896 \ttotal accuracy: 0.8659 \t per class accuracy: 0.8358\n",
      "TRAIN: epoch:  82 \tloss: 0.1407 \taccuracy: 0.9548\n",
      "VALID: epoch:  82 \tloss: 0.4620 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8498\n",
      "TRAIN: epoch:  83 \tloss: 0.1423 \taccuracy: 0.9549\n",
      "VALID: epoch:  83 \tloss: 0.4916 \ttotal accuracy: 0.8683 \t per class accuracy: 0.8459\n",
      "TRAIN: epoch:  84 \tloss: 0.1370 \taccuracy: 0.9556\n",
      "VALID: epoch:  84 \tloss: 0.4641 \ttotal accuracy: 0.8716 \t per class accuracy: 0.8475\n",
      "TRAIN: epoch:  85 \tloss: 0.1281 \taccuracy: 0.9612\n",
      "VALID: epoch:  85 \tloss: 0.4867 \ttotal accuracy: 0.8699 \t per class accuracy: 0.8452\n",
      "TRAIN: epoch:  86 \tloss: 0.1310 \taccuracy: 0.9581\n",
      "VALID: epoch:  86 \tloss: 0.4763 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8560\n",
      "TRAIN: epoch:  87 \tloss: 0.1325 \taccuracy: 0.9588\n",
      "VALID: epoch:  87 \tloss: 0.4800 \ttotal accuracy: 0.8736 \t per class accuracy: 0.8530\n",
      "TRAIN: epoch:  88 \tloss: 0.1236 \taccuracy: 0.9586\n",
      "VALID: epoch:  88 \tloss: 0.4620 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8465\n",
      "TRAIN: epoch:  89 \tloss: 0.1237 \taccuracy: 0.9598\n",
      "VALID: epoch:  89 \tloss: 0.5090 \ttotal accuracy: 0.8679 \t per class accuracy: 0.8427\n",
      "TRAIN: epoch:  90 \tloss: 0.1305 \taccuracy: 0.9575\n",
      "VALID: epoch:  90 \tloss: 0.4770 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8471\n",
      "TRAIN: epoch:  91 \tloss: 0.1267 \taccuracy: 0.9610\n",
      "VALID: epoch:  91 \tloss: 0.5340 \ttotal accuracy: 0.8610 \t per class accuracy: 0.8415\n",
      "TRAIN: epoch:  92 \tloss: 0.1174 \taccuracy: 0.9613\n",
      "VALID: epoch:  92 \tloss: 0.4957 \ttotal accuracy: 0.8671 \t per class accuracy: 0.8491\n",
      "TRAIN: epoch:  93 \tloss: 0.1235 \taccuracy: 0.9602\n",
      "VALID: epoch:  93 \tloss: 0.5000 \ttotal accuracy: 0.8602 \t per class accuracy: 0.8430\n",
      "TRAIN: epoch:  94 \tloss: 0.1177 \taccuracy: 0.9606\n",
      "VALID: epoch:  94 \tloss: 0.4844 \ttotal accuracy: 0.8707 \t per class accuracy: 0.8433\n",
      "TRAIN: epoch:  95 \tloss: 0.1228 \taccuracy: 0.9625\n",
      "VALID: epoch:  95 \tloss: 0.4735 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8432\n",
      "TRAIN: epoch:  96 \tloss: 0.1195 \taccuracy: 0.9613\n",
      "VALID: epoch:  96 \tloss: 0.4834 \ttotal accuracy: 0.8659 \t per class accuracy: 0.8343\n",
      "TRAIN: epoch:  97 \tloss: 0.1136 \taccuracy: 0.9639\n",
      "VALID: epoch:  97 \tloss: 0.5007 \ttotal accuracy: 0.8699 \t per class accuracy: 0.8434\n",
      "TRAIN: epoch:  98 \tloss: 0.1156 \taccuracy: 0.9633\n",
      "VALID: epoch:  98 \tloss: 0.4861 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8530\n",
      "TRAIN: epoch:  99 \tloss: 0.1105 \taccuracy: 0.9643\n",
      "VALID: epoch:  99 \tloss: 0.4909 \ttotal accuracy: 0.8716 \t per class accuracy: 0.8413\n",
      "TRAIN: epoch:  100 \tloss: 0.1118 \taccuracy: 0.9646\n",
      "Model saved in file: log_2/model_100.ckpt\n",
      "VALID: epoch:  100 \tloss: 0.5160 \ttotal accuracy: 0.8639 \t per class accuracy: 0.8362\n",
      "TRAIN: epoch:  101 \tloss: 0.1135 \taccuracy: 0.9640\n",
      "VALID: epoch:  101 \tloss: 0.4896 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8513\n",
      "TRAIN: epoch:  102 \tloss: 0.1092 \taccuracy: 0.9646\n",
      "VALID: epoch:  102 \tloss: 0.4855 \ttotal accuracy: 0.8724 \t per class accuracy: 0.8482\n",
      "TRAIN: epoch:  103 \tloss: 0.1003 \taccuracy: 0.9684\n",
      "VALID: epoch:  103 \tloss: 0.4980 \ttotal accuracy: 0.8744 \t per class accuracy: 0.8497\n",
      "TRAIN: epoch:  104 \tloss: 0.1048 \taccuracy: 0.9668\n",
      "VALID: epoch:  104 \tloss: 0.4834 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8604\n",
      "TRAIN: epoch:  105 \tloss: 0.1009 \taccuracy: 0.9671\n",
      "VALID: epoch:  105 \tloss: 0.4780 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8418\n",
      "TRAIN: epoch:  106 \tloss: 0.1051 \taccuracy: 0.9675\n",
      "VALID: epoch:  106 \tloss: 0.4693 \ttotal accuracy: 0.8776 \t per class accuracy: 0.8516\n",
      "TRAIN: epoch:  107 \tloss: 0.1041 \taccuracy: 0.9665\n",
      "VALID: epoch:  107 \tloss: 0.4920 \ttotal accuracy: 0.8720 \t per class accuracy: 0.8573\n",
      "TRAIN: epoch:  108 \tloss: 0.1043 \taccuracy: 0.9671\n",
      "VALID: epoch:  108 \tloss: 0.4921 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8541\n",
      "TRAIN: epoch:  109 \tloss: 0.1025 \taccuracy: 0.9689\n",
      "VALID: epoch:  109 \tloss: 0.4938 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8557\n",
      "TRAIN: epoch:  110 \tloss: 0.0957 \taccuracy: 0.9697\n",
      "VALID: epoch:  110 \tloss: 0.4680 \ttotal accuracy: 0.8712 \t per class accuracy: 0.8500\n",
      "TRAIN: epoch:  111 \tloss: 0.0943 \taccuracy: 0.9695\n",
      "VALID: epoch:  111 \tloss: 0.4920 \ttotal accuracy: 0.8776 \t per class accuracy: 0.8517\n",
      "TRAIN: epoch:  112 \tloss: 0.0905 \taccuracy: 0.9710\n",
      "VALID: epoch:  112 \tloss: 0.5051 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8455\n",
      "TRAIN: epoch:  113 \tloss: 0.0995 \taccuracy: 0.9676\n",
      "VALID: epoch:  113 \tloss: 0.4997 \ttotal accuracy: 0.8724 \t per class accuracy: 0.8514\n",
      "TRAIN: epoch:  114 \tloss: 0.0895 \taccuracy: 0.9723\n",
      "VALID: epoch:  114 \tloss: 0.5015 \ttotal accuracy: 0.8687 \t per class accuracy: 0.8467\n",
      "TRAIN: epoch:  115 \tloss: 0.0973 \taccuracy: 0.9674\n",
      "VALID: epoch:  115 \tloss: 0.5060 \ttotal accuracy: 0.8679 \t per class accuracy: 0.8518\n",
      "TRAIN: epoch:  116 \tloss: 0.0927 \taccuracy: 0.9687\n",
      "VALID: epoch:  116 \tloss: 0.5018 \ttotal accuracy: 0.8752 \t per class accuracy: 0.8506\n",
      "TRAIN: epoch:  117 \tloss: 0.0941 \taccuracy: 0.9690\n",
      "VALID: epoch:  117 \tloss: 0.5167 \ttotal accuracy: 0.8695 \t per class accuracy: 0.8531\n",
      "TRAIN: epoch:  118 \tloss: 0.0932 \taccuracy: 0.9685\n",
      "VALID: epoch:  118 \tloss: 0.4893 \ttotal accuracy: 0.8784 \t per class accuracy: 0.8550\n",
      "TRAIN: epoch:  119 \tloss: 0.0866 \taccuracy: 0.9720\n",
      "VALID: epoch:  119 \tloss: 0.5258 \ttotal accuracy: 0.8699 \t per class accuracy: 0.8459\n",
      "TRAIN: epoch:  120 \tloss: 0.0870 \taccuracy: 0.9716\n",
      "VALID: epoch:  120 \tloss: 0.5076 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8495\n",
      "TRAIN: epoch:  121 \tloss: 0.0878 \taccuracy: 0.9705\n",
      "VALID: epoch:  121 \tloss: 0.4791 \ttotal accuracy: 0.8849 \t per class accuracy: 0.8587\n",
      "TRAIN: epoch:  122 \tloss: 0.0854 \taccuracy: 0.9721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID: epoch:  122 \tloss: 0.4945 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8526\n",
      "TRAIN: epoch:  123 \tloss: 0.0827 \taccuracy: 0.9739\n",
      "VALID: epoch:  123 \tloss: 0.5067 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8459\n",
      "TRAIN: epoch:  124 \tloss: 0.0800 \taccuracy: 0.9733\n",
      "VALID: epoch:  124 \tloss: 0.5026 \ttotal accuracy: 0.8817 \t per class accuracy: 0.8562\n",
      "TRAIN: epoch:  125 \tloss: 0.0779 \taccuracy: 0.9750\n",
      "VALID: epoch:  125 \tloss: 0.5248 \ttotal accuracy: 0.8663 \t per class accuracy: 0.8436\n",
      "TRAIN: epoch:  126 \tloss: 0.0773 \taccuracy: 0.9744\n",
      "VALID: epoch:  126 \tloss: 0.4862 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8444\n",
      "TRAIN: epoch:  127 \tloss: 0.0739 \taccuracy: 0.9760\n",
      "VALID: epoch:  127 \tloss: 0.4927 \ttotal accuracy: 0.8675 \t per class accuracy: 0.8432\n",
      "TRAIN: epoch:  128 \tloss: 0.0766 \taccuracy: 0.9757\n",
      "VALID: epoch:  128 \tloss: 0.5123 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8462\n",
      "TRAIN: epoch:  129 \tloss: 0.0728 \taccuracy: 0.9774\n",
      "VALID: epoch:  129 \tloss: 0.4948 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8465\n",
      "TRAIN: epoch:  130 \tloss: 0.0716 \taccuracy: 0.9786\n",
      "VALID: epoch:  130 \tloss: 0.5109 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8445\n",
      "TRAIN: epoch:  131 \tloss: 0.0719 \taccuracy: 0.9767\n",
      "VALID: epoch:  131 \tloss: 0.5043 \ttotal accuracy: 0.8805 \t per class accuracy: 0.8516\n",
      "TRAIN: epoch:  132 \tloss: 0.0704 \taccuracy: 0.9774\n",
      "VALID: epoch:  132 \tloss: 0.5032 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8473\n",
      "TRAIN: epoch:  133 \tloss: 0.0754 \taccuracy: 0.9753\n",
      "VALID: epoch:  133 \tloss: 0.4909 \ttotal accuracy: 0.8776 \t per class accuracy: 0.8528\n",
      "TRAIN: epoch:  134 \tloss: 0.0698 \taccuracy: 0.9766\n",
      "VALID: epoch:  134 \tloss: 0.5077 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8474\n",
      "TRAIN: epoch:  135 \tloss: 0.0712 \taccuracy: 0.9780\n",
      "VALID: epoch:  135 \tloss: 0.5151 \ttotal accuracy: 0.8691 \t per class accuracy: 0.8444\n",
      "TRAIN: epoch:  136 \tloss: 0.0730 \taccuracy: 0.9754\n",
      "VALID: epoch:  136 \tloss: 0.5083 \ttotal accuracy: 0.8736 \t per class accuracy: 0.8460\n",
      "TRAIN: epoch:  137 \tloss: 0.0700 \taccuracy: 0.9771\n",
      "VALID: epoch:  137 \tloss: 0.4947 \ttotal accuracy: 0.8821 \t per class accuracy: 0.8608\n",
      "TRAIN: epoch:  138 \tloss: 0.0685 \taccuracy: 0.9779\n",
      "VALID: epoch:  138 \tloss: 0.5155 \ttotal accuracy: 0.8756 \t per class accuracy: 0.8499\n",
      "TRAIN: epoch:  139 \tloss: 0.0721 \taccuracy: 0.9758\n",
      "VALID: epoch:  139 \tloss: 0.5107 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8485\n",
      "TRAIN: epoch:  140 \tloss: 0.0659 \taccuracy: 0.9792\n",
      "VALID: epoch:  140 \tloss: 0.5073 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8598\n",
      "TRAIN: epoch:  141 \tloss: 0.0703 \taccuracy: 0.9759\n",
      "VALID: epoch:  141 \tloss: 0.4955 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8577\n",
      "TRAIN: epoch:  142 \tloss: 0.0635 \taccuracy: 0.9792\n",
      "VALID: epoch:  142 \tloss: 0.5047 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8531\n",
      "TRAIN: epoch:  143 \tloss: 0.0651 \taccuracy: 0.9777\n",
      "VALID: epoch:  143 \tloss: 0.4952 \ttotal accuracy: 0.8784 \t per class accuracy: 0.8590\n",
      "TRAIN: epoch:  144 \tloss: 0.0594 \taccuracy: 0.9815\n",
      "VALID: epoch:  144 \tloss: 0.4986 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8499\n",
      "TRAIN: epoch:  145 \tloss: 0.0566 \taccuracy: 0.9818\n",
      "VALID: epoch:  145 \tloss: 0.4873 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8516\n",
      "TRAIN: epoch:  146 \tloss: 0.0604 \taccuracy: 0.9803\n",
      "VALID: epoch:  146 \tloss: 0.5231 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8543\n",
      "TRAIN: epoch:  147 \tloss: 0.0627 \taccuracy: 0.9800\n",
      "VALID: epoch:  147 \tloss: 0.5030 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8484\n",
      "TRAIN: epoch:  148 \tloss: 0.0588 \taccuracy: 0.9814\n",
      "VALID: epoch:  148 \tloss: 0.4945 \ttotal accuracy: 0.8805 \t per class accuracy: 0.8569\n",
      "TRAIN: epoch:  149 \tloss: 0.0550 \taccuracy: 0.9809\n",
      "VALID: epoch:  149 \tloss: 0.5009 \ttotal accuracy: 0.8772 \t per class accuracy: 0.8498\n",
      "TRAIN: epoch:  150 \tloss: 0.0556 \taccuracy: 0.9803\n",
      "Model saved in file: log_2/model_150.ckpt\n",
      "VALID: epoch:  150 \tloss: 0.5086 \ttotal accuracy: 0.8752 \t per class accuracy: 0.8493\n",
      "TRAIN: epoch:  151 \tloss: 0.0568 \taccuracy: 0.9822\n",
      "VALID: epoch:  151 \tloss: 0.5001 \ttotal accuracy: 0.8712 \t per class accuracy: 0.8508\n",
      "TRAIN: epoch:  152 \tloss: 0.0580 \taccuracy: 0.9810\n",
      "VALID: epoch:  152 \tloss: 0.5137 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8568\n",
      "TRAIN: epoch:  153 \tloss: 0.0532 \taccuracy: 0.9825\n",
      "VALID: epoch:  153 \tloss: 0.5196 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8553\n",
      "TRAIN: epoch:  154 \tloss: 0.0576 \taccuracy: 0.9807\n",
      "VALID: epoch:  154 \tloss: 0.4938 \ttotal accuracy: 0.8793 \t per class accuracy: 0.8574\n",
      "TRAIN: epoch:  155 \tloss: 0.0559 \taccuracy: 0.9835\n",
      "VALID: epoch:  155 \tloss: 0.4904 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8590\n",
      "TRAIN: epoch:  156 \tloss: 0.0543 \taccuracy: 0.9824\n",
      "VALID: epoch:  156 \tloss: 0.5020 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8510\n",
      "TRAIN: epoch:  157 \tloss: 0.0581 \taccuracy: 0.9812\n",
      "VALID: epoch:  157 \tloss: 0.4905 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8512\n",
      "TRAIN: epoch:  158 \tloss: 0.0552 \taccuracy: 0.9822\n",
      "VALID: epoch:  158 \tloss: 0.4990 \ttotal accuracy: 0.8805 \t per class accuracy: 0.8548\n",
      "TRAIN: epoch:  159 \tloss: 0.0548 \taccuracy: 0.9830\n",
      "VALID: epoch:  159 \tloss: 0.5033 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8485\n",
      "TRAIN: epoch:  160 \tloss: 0.0529 \taccuracy: 0.9825\n",
      "VALID: epoch:  160 \tloss: 0.4919 \ttotal accuracy: 0.8817 \t per class accuracy: 0.8535\n",
      "TRAIN: epoch:  161 \tloss: 0.0540 \taccuracy: 0.9821\n",
      "VALID: epoch:  161 \tloss: 0.5250 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8524\n",
      "TRAIN: epoch:  162 \tloss: 0.0522 \taccuracy: 0.9826\n",
      "VALID: epoch:  162 \tloss: 0.5014 \ttotal accuracy: 0.8732 \t per class accuracy: 0.8446\n",
      "TRAIN: epoch:  163 \tloss: 0.0533 \taccuracy: 0.9832\n",
      "VALID: epoch:  163 \tloss: 0.5139 \ttotal accuracy: 0.8764 \t per class accuracy: 0.8490\n",
      "TRAIN: epoch:  164 \tloss: 0.0474 \taccuracy: 0.9847\n",
      "VALID: epoch:  164 \tloss: 0.4995 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8511\n",
      "TRAIN: epoch:  165 \tloss: 0.0457 \taccuracy: 0.9856\n",
      "VALID: epoch:  165 \tloss: 0.5040 \ttotal accuracy: 0.8764 \t per class accuracy: 0.8537\n",
      "TRAIN: epoch:  166 \tloss: 0.0501 \taccuracy: 0.9830\n",
      "VALID: epoch:  166 \tloss: 0.5104 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8617\n",
      "TRAIN: epoch:  167 \tloss: 0.0509 \taccuracy: 0.9831\n",
      "VALID: epoch:  167 \tloss: 0.5159 \ttotal accuracy: 0.8748 \t per class accuracy: 0.8586\n",
      "TRAIN: epoch:  168 \tloss: 0.0459 \taccuracy: 0.9848\n",
      "VALID: epoch:  168 \tloss: 0.5056 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8478\n",
      "TRAIN: epoch:  169 \tloss: 0.0479 \taccuracy: 0.9837\n",
      "VALID: epoch:  169 \tloss: 0.5423 \ttotal accuracy: 0.8728 \t per class accuracy: 0.8515\n",
      "TRAIN: epoch:  170 \tloss: 0.0498 \taccuracy: 0.9829\n",
      "VALID: epoch:  170 \tloss: 0.5136 \ttotal accuracy: 0.8825 \t per class accuracy: 0.8573\n",
      "TRAIN: epoch:  171 \tloss: 0.0488 \taccuracy: 0.9846\n",
      "VALID: epoch:  171 \tloss: 0.5022 \ttotal accuracy: 0.8841 \t per class accuracy: 0.8636\n",
      "TRAIN: epoch:  172 \tloss: 0.0487 \taccuracy: 0.9837\n",
      "VALID: epoch:  172 \tloss: 0.4976 \ttotal accuracy: 0.8861 \t per class accuracy: 0.8641\n",
      "TRAIN: epoch:  173 \tloss: 0.0484 \taccuracy: 0.9831\n",
      "VALID: epoch:  173 \tloss: 0.5138 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8571\n",
      "TRAIN: epoch:  174 \tloss: 0.0484 \taccuracy: 0.9847\n",
      "VALID: epoch:  174 \tloss: 0.5101 \ttotal accuracy: 0.8772 \t per class accuracy: 0.8537\n",
      "TRAIN: epoch:  175 \tloss: 0.0459 \taccuracy: 0.9849\n",
      "VALID: epoch:  175 \tloss: 0.4978 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8600\n",
      "TRAIN: epoch:  176 \tloss: 0.0489 \taccuracy: 0.9830\n",
      "VALID: epoch:  176 \tloss: 0.5251 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8533\n",
      "TRAIN: epoch:  177 \tloss: 0.0471 \taccuracy: 0.9842\n",
      "VALID: epoch:  177 \tloss: 0.5141 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8574\n",
      "TRAIN: epoch:  178 \tloss: 0.0441 \taccuracy: 0.9842\n",
      "VALID: epoch:  178 \tloss: 0.4963 \ttotal accuracy: 0.8902 \t per class accuracy: 0.8679\n",
      "TRAIN: epoch:  179 \tloss: 0.0517 \taccuracy: 0.9823\n",
      "VALID: epoch:  179 \tloss: 0.5177 \ttotal accuracy: 0.8740 \t per class accuracy: 0.8552\n",
      "TRAIN: epoch:  180 \tloss: 0.0475 \taccuracy: 0.9845\n",
      "VALID: epoch:  180 \tloss: 0.5214 \ttotal accuracy: 0.8821 \t per class accuracy: 0.8608\n",
      "TRAIN: epoch:  181 \tloss: 0.0468 \taccuracy: 0.9850\n",
      "VALID: epoch:  181 \tloss: 0.4972 \ttotal accuracy: 0.8833 \t per class accuracy: 0.8616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:  182 \tloss: 0.0442 \taccuracy: 0.9855\n",
      "VALID: epoch:  182 \tloss: 0.5029 \ttotal accuracy: 0.8849 \t per class accuracy: 0.8606\n",
      "TRAIN: epoch:  183 \tloss: 0.0451 \taccuracy: 0.9843\n",
      "VALID: epoch:  183 \tloss: 0.5151 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8598\n",
      "TRAIN: epoch:  184 \tloss: 0.0418 \taccuracy: 0.9858\n",
      "VALID: epoch:  184 \tloss: 0.5227 \ttotal accuracy: 0.8764 \t per class accuracy: 0.8573\n",
      "TRAIN: epoch:  185 \tloss: 0.0432 \taccuracy: 0.9840\n",
      "VALID: epoch:  185 \tloss: 0.5081 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8584\n",
      "TRAIN: epoch:  186 \tloss: 0.0413 \taccuracy: 0.9856\n",
      "VALID: epoch:  186 \tloss: 0.5048 \ttotal accuracy: 0.8837 \t per class accuracy: 0.8577\n",
      "TRAIN: epoch:  187 \tloss: 0.0414 \taccuracy: 0.9853\n",
      "VALID: epoch:  187 \tloss: 0.5166 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8535\n",
      "TRAIN: epoch:  188 \tloss: 0.0426 \taccuracy: 0.9852\n",
      "VALID: epoch:  188 \tloss: 0.5053 \ttotal accuracy: 0.8780 \t per class accuracy: 0.8536\n",
      "TRAIN: epoch:  189 \tloss: 0.0405 \taccuracy: 0.9855\n",
      "VALID: epoch:  189 \tloss: 0.5138 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8497\n",
      "TRAIN: epoch:  190 \tloss: 0.0413 \taccuracy: 0.9845\n",
      "VALID: epoch:  190 \tloss: 0.5148 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8555\n",
      "TRAIN: epoch:  191 \tloss: 0.0413 \taccuracy: 0.9853\n",
      "VALID: epoch:  191 \tloss: 0.5157 \ttotal accuracy: 0.8768 \t per class accuracy: 0.8558\n",
      "TRAIN: epoch:  192 \tloss: 0.0400 \taccuracy: 0.9865\n",
      "VALID: epoch:  192 \tloss: 0.5307 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8572\n",
      "TRAIN: epoch:  193 \tloss: 0.0411 \taccuracy: 0.9866\n",
      "VALID: epoch:  193 \tloss: 0.5259 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8567\n",
      "TRAIN: epoch:  194 \tloss: 0.0418 \taccuracy: 0.9856\n",
      "VALID: epoch:  194 \tloss: 0.5239 \ttotal accuracy: 0.8841 \t per class accuracy: 0.8625\n",
      "TRAIN: epoch:  195 \tloss: 0.0414 \taccuracy: 0.9853\n",
      "VALID: epoch:  195 \tloss: 0.5121 \ttotal accuracy: 0.8797 \t per class accuracy: 0.8571\n",
      "TRAIN: epoch:  196 \tloss: 0.0395 \taccuracy: 0.9869\n",
      "VALID: epoch:  196 \tloss: 0.5208 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8526\n",
      "TRAIN: epoch:  197 \tloss: 0.0392 \taccuracy: 0.9859\n",
      "VALID: epoch:  197 \tloss: 0.5234 \ttotal accuracy: 0.8760 \t per class accuracy: 0.8507\n",
      "TRAIN: epoch:  198 \tloss: 0.0400 \taccuracy: 0.9867\n",
      "VALID: epoch:  198 \tloss: 0.5319 \ttotal accuracy: 0.8764 \t per class accuracy: 0.8562\n",
      "TRAIN: epoch:  199 \tloss: 0.0395 \taccuracy: 0.9867\n",
      "VALID: epoch:  199 \tloss: 0.5224 \ttotal accuracy: 0.8784 \t per class accuracy: 0.8524\n",
      "TRAIN: epoch:  200 \tloss: 0.0385 \taccuracy: 0.9880\n",
      "Model saved in file: log_2/model_200.ckpt\n",
      "VALID: epoch:  200 \tloss: 0.5080 \ttotal accuracy: 0.8841 \t per class accuracy: 0.8592\n",
      "TRAIN: epoch:  201 \tloss: 0.0407 \taccuracy: 0.9860\n",
      "VALID: epoch:  201 \tloss: 0.5222 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8525\n",
      "TRAIN: epoch:  202 \tloss: 0.0395 \taccuracy: 0.9863\n",
      "VALID: epoch:  202 \tloss: 0.5234 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8511\n",
      "TRAIN: epoch:  203 \tloss: 0.0403 \taccuracy: 0.9862\n",
      "VALID: epoch:  203 \tloss: 0.5244 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8579\n",
      "TRAIN: epoch:  204 \tloss: 0.0389 \taccuracy: 0.9877\n",
      "VALID: epoch:  204 \tloss: 0.5127 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8567\n",
      "TRAIN: epoch:  205 \tloss: 0.0378 \taccuracy: 0.9874\n",
      "VALID: epoch:  205 \tloss: 0.5214 \ttotal accuracy: 0.8784 \t per class accuracy: 0.8545\n",
      "TRAIN: epoch:  206 \tloss: 0.0357 \taccuracy: 0.9880\n",
      "VALID: epoch:  206 \tloss: 0.5328 \ttotal accuracy: 0.8829 \t per class accuracy: 0.8619\n",
      "TRAIN: epoch:  207 \tloss: 0.0379 \taccuracy: 0.9879\n",
      "VALID: epoch:  207 \tloss: 0.5077 \ttotal accuracy: 0.8829 \t per class accuracy: 0.8553\n",
      "TRAIN: epoch:  208 \tloss: 0.0374 \taccuracy: 0.9878\n",
      "VALID: epoch:  208 \tloss: 0.5076 \ttotal accuracy: 0.8857 \t per class accuracy: 0.8618\n",
      "TRAIN: epoch:  209 \tloss: 0.0372 \taccuracy: 0.9877\n",
      "VALID: epoch:  209 \tloss: 0.5190 \ttotal accuracy: 0.8793 \t per class accuracy: 0.8580\n",
      "TRAIN: epoch:  210 \tloss: 0.0382 \taccuracy: 0.9859\n",
      "VALID: epoch:  210 \tloss: 0.5055 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8572\n",
      "TRAIN: epoch:  211 \tloss: 0.0387 \taccuracy: 0.9856\n",
      "VALID: epoch:  211 \tloss: 0.5120 \ttotal accuracy: 0.8845 \t per class accuracy: 0.8585\n",
      "TRAIN: epoch:  212 \tloss: 0.0363 \taccuracy: 0.9869\n",
      "VALID: epoch:  212 \tloss: 0.5247 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8564\n",
      "TRAIN: epoch:  213 \tloss: 0.0359 \taccuracy: 0.9874\n",
      "VALID: epoch:  213 \tloss: 0.5096 \ttotal accuracy: 0.8805 \t per class accuracy: 0.8583\n",
      "TRAIN: epoch:  214 \tloss: 0.0363 \taccuracy: 0.9877\n",
      "VALID: epoch:  214 \tloss: 0.5192 \ttotal accuracy: 0.8821 \t per class accuracy: 0.8560\n",
      "TRAIN: epoch:  215 \tloss: 0.0370 \taccuracy: 0.9871\n",
      "VALID: epoch:  215 \tloss: 0.5089 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8581\n",
      "TRAIN: epoch:  216 \tloss: 0.0369 \taccuracy: 0.9866\n",
      "VALID: epoch:  216 \tloss: 0.5148 \ttotal accuracy: 0.8788 \t per class accuracy: 0.8488\n",
      "TRAIN: epoch:  217 \tloss: 0.0355 \taccuracy: 0.9873\n",
      "VALID: epoch:  217 \tloss: 0.5237 \ttotal accuracy: 0.8825 \t per class accuracy: 0.8570\n",
      "TRAIN: epoch:  218 \tloss: 0.0350 \taccuracy: 0.9882\n",
      "VALID: epoch:  218 \tloss: 0.5146 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8580\n",
      "TRAIN: epoch:  219 \tloss: 0.0361 \taccuracy: 0.9874\n",
      "VALID: epoch:  219 \tloss: 0.5150 \ttotal accuracy: 0.8865 \t per class accuracy: 0.8614\n",
      "TRAIN: epoch:  220 \tloss: 0.0370 \taccuracy: 0.9871\n",
      "VALID: epoch:  220 \tloss: 0.5213 \ttotal accuracy: 0.8833 \t per class accuracy: 0.8565\n",
      "TRAIN: epoch:  221 \tloss: 0.0367 \taccuracy: 0.9868\n",
      "VALID: epoch:  221 \tloss: 0.5091 \ttotal accuracy: 0.8825 \t per class accuracy: 0.8533\n",
      "TRAIN: epoch:  222 \tloss: 0.0354 \taccuracy: 0.9871\n",
      "VALID: epoch:  222 \tloss: 0.5167 \ttotal accuracy: 0.8837 \t per class accuracy: 0.8596\n",
      "TRAIN: epoch:  223 \tloss: 0.0360 \taccuracy: 0.9882\n",
      "VALID: epoch:  223 \tloss: 0.5391 \ttotal accuracy: 0.8809 \t per class accuracy: 0.8586\n",
      "TRAIN: epoch:  224 \tloss: 0.0362 \taccuracy: 0.9876\n",
      "VALID: epoch:  224 \tloss: 0.5322 \ttotal accuracy: 0.8772 \t per class accuracy: 0.8558\n",
      "TRAIN: epoch:  225 \tloss: 0.0345 \taccuracy: 0.9885\n",
      "VALID: epoch:  225 \tloss: 0.5305 \ttotal accuracy: 0.8793 \t per class accuracy: 0.8523\n",
      "TRAIN: epoch:  226 \tloss: 0.0352 \taccuracy: 0.9874\n",
      "VALID: epoch:  226 \tloss: 0.5293 \ttotal accuracy: 0.8797 \t per class accuracy: 0.8576\n",
      "TRAIN: epoch:  227 \tloss: 0.0350 \taccuracy: 0.9878\n",
      "VALID: epoch:  227 \tloss: 0.5204 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8519\n",
      "TRAIN: epoch:  228 \tloss: 0.0348 \taccuracy: 0.9877\n",
      "VALID: epoch:  228 \tloss: 0.5216 \ttotal accuracy: 0.8793 \t per class accuracy: 0.8552\n",
      "TRAIN: epoch:  229 \tloss: 0.0346 \taccuracy: 0.9869\n",
      "VALID: epoch:  229 \tloss: 0.5311 \ttotal accuracy: 0.8805 \t per class accuracy: 0.8530\n",
      "TRAIN: epoch:  230 \tloss: 0.0335 \taccuracy: 0.9886\n",
      "VALID: epoch:  230 \tloss: 0.5072 \ttotal accuracy: 0.8829 \t per class accuracy: 0.8556\n",
      "TRAIN: epoch:  231 \tloss: 0.0342 \taccuracy: 0.9878\n",
      "VALID: epoch:  231 \tloss: 0.5092 \ttotal accuracy: 0.8833 \t per class accuracy: 0.8588\n",
      "TRAIN: epoch:  232 \tloss: 0.0338 \taccuracy: 0.9885\n",
      "VALID: epoch:  232 \tloss: 0.5110 \ttotal accuracy: 0.8825 \t per class accuracy: 0.8574\n",
      "TRAIN: epoch:  233 \tloss: 0.0336 \taccuracy: 0.9889\n",
      "VALID: epoch:  233 \tloss: 0.5137 \ttotal accuracy: 0.8878 \t per class accuracy: 0.8645\n",
      "TRAIN: epoch:  234 \tloss: 0.0339 \taccuracy: 0.9883\n",
      "VALID: epoch:  234 \tloss: 0.5316 \ttotal accuracy: 0.8801 \t per class accuracy: 0.8565\n",
      "TRAIN: epoch:  235 \tloss: 0.0361 \taccuracy: 0.9877\n",
      "VALID: epoch:  235 \tloss: 0.5247 \ttotal accuracy: 0.8837 \t per class accuracy: 0.8610\n",
      "TRAIN: epoch:  236 \tloss: 0.0341 \taccuracy: 0.9874\n",
      "VALID: epoch:  236 \tloss: 0.5076 \ttotal accuracy: 0.8861 \t per class accuracy: 0.8640\n",
      "TRAIN: epoch:  237 \tloss: 0.0338 \taccuracy: 0.9878\n",
      "VALID: epoch:  237 \tloss: 0.5250 \ttotal accuracy: 0.8817 \t per class accuracy: 0.8578\n",
      "TRAIN: epoch:  238 \tloss: 0.0343 \taccuracy: 0.9881\n",
      "VALID: epoch:  238 \tloss: 0.5291 \ttotal accuracy: 0.8797 \t per class accuracy: 0.8542\n",
      "TRAIN: epoch:  239 \tloss: 0.0341 \taccuracy: 0.9871\n",
      "VALID: epoch:  239 \tloss: 0.5216 \ttotal accuracy: 0.8776 \t per class accuracy: 0.8501\n",
      "TRAIN: epoch:  240 \tloss: 0.0339 \taccuracy: 0.9877\n",
      "VALID: epoch:  240 \tloss: 0.5121 \ttotal accuracy: 0.8825 \t per class accuracy: 0.8540\n",
      "TRAIN: epoch:  241 \tloss: 0.0334 \taccuracy: 0.9890\n",
      "VALID: epoch:  241 \tloss: 0.5339 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: epoch:  242 \tloss: 0.0319 \taccuracy: 0.9892\n",
      "VALID: epoch:  242 \tloss: 0.5228 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8532\n",
      "TRAIN: epoch:  243 \tloss: 0.0347 \taccuracy: 0.9883\n",
      "VALID: epoch:  243 \tloss: 0.5199 \ttotal accuracy: 0.8845 \t per class accuracy: 0.8569\n",
      "TRAIN: epoch:  244 \tloss: 0.0338 \taccuracy: 0.9870\n",
      "VALID: epoch:  244 \tloss: 0.5231 \ttotal accuracy: 0.8813 \t per class accuracy: 0.8563\n",
      "TRAIN: epoch:  245 \tloss: 0.0307 \taccuracy: 0.9890\n",
      "VALID: epoch:  245 \tloss: 0.5375 \ttotal accuracy: 0.8793 \t per class accuracy: 0.8524\n",
      "TRAIN: epoch:  246 \tloss: 0.0321 \taccuracy: 0.9877\n",
      "VALID: epoch:  246 \tloss: 0.5180 \ttotal accuracy: 0.8821 \t per class accuracy: 0.8586\n",
      "TRAIN: epoch:  247 \tloss: 0.0306 \taccuracy: 0.9891\n",
      "VALID: epoch:  247 \tloss: 0.5154 \ttotal accuracy: 0.8833 \t per class accuracy: 0.8589\n",
      "TRAIN: epoch:  248 \tloss: 0.0318 \taccuracy: 0.9889\n",
      "VALID: epoch:  248 \tloss: 0.5047 \ttotal accuracy: 0.8829 \t per class accuracy: 0.8588\n",
      "TRAIN: epoch:  249 \tloss: 0.0335 \taccuracy: 0.9879\n",
      "VALID: epoch:  249 \tloss: 0.5123 \ttotal accuracy: 0.8849 \t per class accuracy: 0.8599\n",
      "TRAIN: epoch:  250 \tloss: 0.0315 \taccuracy: 0.9883\n",
      "Model saved in file: log_2/model_250.ckpt\n",
      "VALID: epoch:  250 \tloss: 0.5005 \ttotal accuracy: 0.8849 \t per class accuracy: 0.8619\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_point = 1024\n",
    "max_epoch = 250\n",
    "\n",
    "num_train = train_label.shape[0]\n",
    "num_test = test_label.shape[0]\n",
    "\n",
    "LOG_DIR = 'log_2'\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    batch_num = np.ceil(num_train/batch_size).astype(int)\n",
    "    batch_num_test = np.ceil(num_test/batch_size).astype(int)\n",
    "    for epoch in range(max_epoch):\n",
    "        # shuffle the data for each epoch\n",
    "        idx = np.arange(num_train)\n",
    "        np.random.shuffle(idx)\n",
    "        train_data = train_data[idx, ...]\n",
    "        train_label = train_label[idx]\n",
    "        loss_train_all = 0\n",
    "        acc_train_all = 0\n",
    "        for batch_idx in range(batch_num):\n",
    "            start_idx = batch_idx*batch_size\n",
    "            end_idx = np.min([(batch_idx+1)*batch_size,num_train-1])\n",
    "            feed_data = train_data[start_idx:end_idx,...]\n",
    "            rotation_data = rotation_pointcloud(feed_data)\n",
    "            augment_data = jittering_pointcloud(rotation_data)\n",
    "            sess.run([model_train],{X: augment_data, \\\n",
    "                                    label: train_label[start_idx:end_idx], is_training: True})            \n",
    "            summary,loss_train,acc_train,log_step = sess.run([merged,loss,accuracy,batch], \\\n",
    "                                        {X: augment_data, \\\n",
    "                                         label: train_label[start_idx:end_idx], is_training: False})\n",
    "            train_writer.add_summary(summary, log_step)\n",
    "            loss_train_all = loss_train_all + loss_train*(end_idx-start_idx)\n",
    "            acc_train_all = acc_train_all + acc_train*(end_idx-start_idx)\n",
    "        loss_train_all = loss_train_all / num_train\n",
    "        acc_train_all = acc_train_all / num_train        \n",
    "        print('TRAIN: epoch: ', epoch+1, '\\tloss: %.4f'%loss_train_all, '\\taccuracy: %.4f'%acc_train_all)\n",
    "        if (epoch+1) % 50 == 0:\n",
    "            save_path = saver.save(sess, os.path.join(LOG_DIR, \"model_\"+str(epoch+1)+\".ckpt\"))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "        \n",
    "        # validation\n",
    "        loss_val_all = 0\n",
    "        acc_val_all = 0\n",
    "        total_seen_class = np.zeros(40)\n",
    "        total_correct_class = np.zeros(40)\n",
    "        for batch_idx in range(batch_num_test):\n",
    "            start_idx = batch_idx*batch_size\n",
    "            end_idx = np.min([(batch_idx+1)*batch_size,num_test-1])\n",
    "            feed_data = test_data[start_idx:end_idx,...]\n",
    "            rotation_data = rotation_pointcloud(feed_data)\n",
    "            summary,pred,loss_val,acc_val,log_step = sess.run([merged,predict,loss,accuracy,batch], \\\n",
    "                                        {X: rotation_data, \\\n",
    "                                         label: test_label[start_idx:end_idx], is_training: False})\n",
    "            test_writer.add_summary(summary, log_step)\n",
    "            loss_val_all = loss_val_all + loss_val*(end_idx-start_idx)\n",
    "            acc_val_all = acc_val_all + acc_val*(end_idx-start_idx)\n",
    "            for c_index in range(start_idx, end_idx):\n",
    "                current_class = test_label[c_index]\n",
    "                total_seen_class[current_class] += 1\n",
    "                total_correct_class[current_class] += (pred[c_index-start_idx]==current_class)           \n",
    "        loss_val_all = loss_val_all / num_test\n",
    "        acc_val_all = acc_val_all / num_test\n",
    "        acc_avg_class = np.mean(total_correct_class/total_seen_class)\n",
    "        print('VALID: epoch: ', epoch+1, '\\tloss: %.4f'%loss_val_all, \\\n",
    "              '\\ttotal accuracy: %.4f'%acc_val_all, \\\n",
    "              '\\t per class accuracy: %.4f'%acc_avg_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f822abae320>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "# for display visualization\n",
    "# only in jupyter notebook\n",
    "points = pd.DataFrame(test_data[200], columns=['x', 'y', 'z'])\n",
    "cloud = PyntCloud(points)\n",
    "cloud.plot(lines=[], line_color=[], point_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f81f7797908>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "# for display visualization\n",
    "# only in jupyter notebook\n",
    "points = pd.DataFrame(rotation_test[200], columns=['x', 'y', 'z'])\n",
    "cloud = PyntCloud(points)\n",
    "cloud.plot(lines=[], line_color=[], point_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log_2/model_250.ckpt\n",
      "VALID: epoch:  1 \tloss: 0.5166 \ttotal accuracy: 0.8833 \t per class accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_point = 1024\n",
    "\n",
    "num_train = train_label.shape[0]\n",
    "num_test = test_label.shape[0]\n",
    "\n",
    "MODEL_PATH = 'log_2/model_250.ckpt'\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, MODEL_PATH)  \n",
    "    batch_num = np.ceil(num_train/batch_size).astype(int)\n",
    "    batch_num_test = np.ceil(num_test/batch_size).astype(int)\n",
    "    for epoch in range(1):\n",
    "        # shuffle the data for each epoch\n",
    "        idx = np.arange(num_test)\n",
    "        np.random.shuffle(idx)\n",
    "        test_data = test_data[idx, ...]\n",
    "        test_label = test_label[idx]\n",
    "        # validation\n",
    "        loss_val_all = 0\n",
    "        acc_val_all = 0\n",
    "        total_seen_class = np.zeros(40)\n",
    "        total_correct_class = np.zeros(40)\n",
    "        for batch_idx in range(batch_num_test):\n",
    "            start_idx = batch_idx*batch_size\n",
    "            end_idx = np.min([(batch_idx+1)*batch_size,num_test-1])\n",
    "            feed_data = test_data[start_idx:end_idx,...]\n",
    "            feed_data = rotation_pointcloud(feed_data)\n",
    "            feed_data = jittering_pointcloud(feed_data)\n",
    "            pred,loss_val,acc_val,log_step = sess.run([predict,loss,accuracy,batch], \\\n",
    "                                        {X: feed_data, \\\n",
    "                                         label: test_label[start_idx:end_idx], is_training: False})\n",
    "            loss_val_all = loss_val_all + loss_val*(end_idx-start_idx)\n",
    "            acc_val_all = acc_val_all + acc_val*(end_idx-start_idx)\n",
    "            for c_index in range(start_idx, end_idx):\n",
    "                current_class = test_label[c_index]\n",
    "                total_seen_class[current_class] += 1\n",
    "                total_correct_class[current_class] += (pred[c_index-start_idx]==current_class)           \n",
    "        loss_val_all = loss_val_all / num_test\n",
    "        acc_val_all = acc_val_all / num_test\n",
    "        acc_avg_class = np.mean(total_correct_class/total_seen_class)\n",
    "        print('VALID: epoch: ', epoch+1, '\\tloss: %.4f'%loss_val_all, \\\n",
    "              '\\ttotal accuracy: %.4f'%acc_val_all, \\\n",
    "              '\\t per class accuracy: %.4f'%acc_avg_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
